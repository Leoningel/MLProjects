{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook we did research on the features of the data set and had a look at the data preprocessing necessary for our project. Based on this research, we made decisions concerning outlier treatment, imputation of missing values, binning, one-hot encoding, and scaling. Let's first understand the reason to use these processing measures.\n",
    "\n",
    "**Outlier treatment:**\n",
    "Data can have mistakes, deriving for multiple reasons. These outliers can have undesirable effects when analysing the data. As these outliers are mostly the result of (human) errors, we want to take these out. Therefore we apply an outlier treatment, namely capping our data set per feature. The cap is set at 3 standard deviations from the mean for every continuous variable (3 standard deviations below and above the mean).\n",
    "\n",
    "**Imputation of missing values:**\n",
    "Also known as gap-filling, this methods concerns artificially completing a data set by imputing missing values. Sometimes information is missing from certain instances of a data set. If this information is not all important, we don't simply want to remove the whole instance as there is still information available. What we did for missing values is to make an intelligent guess of the missing information. We decided on a method per feature.\n",
    "\n",
    "**Binning:**\n",
    "Binning is important for two reasons:\n",
    "* it makes computations a lot faster.\n",
    "* on a conceptual level binning categorizes a continuous variable. This makes it easy for the model to understand that variable. For example, we frequently do binning without realizing: when somebody says an album was released 1967 we automatically think it was released in the 60's and that in itself is a valuable piece of information.\n",
    "\n",
    "Binning was done for all continuous variables.\n",
    "\n",
    "**One-hot encoding:**\n",
    "Also known as label encoding, this method solves the issue of categorical values. Mostly, categorical values do not have a natural distance assigned. As most machine learning methods work with distances (less/greater or equal than), this is an obstacle. By one-hot-encoding, we solve this issue.\n",
    "\n",
    "**Scaling:**\n",
    "Some of our machine learning algorithms are based on finding the most 'similar' data point, where similaraity is measured by distances. If the domain of a certain feature is of a different scale than another, the impact of this feature on the distances between the data point will differ as well. For example, suppose we're looking at the weight in kg and the length in m of people. A difference of 0.30 kg we would consider as a minor difference, whereas a difference of 0.30 m, would be considered as a major difference. Still the impact on the distance between two points would be treated the same. Therefore we want to standardise the feature domains.\n",
    "\n",
    "The rest of this notebook will be take the reader through our findings and methods of preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import iqr\n",
    "%pprint #disables pretty printing to see printed lists horizontally\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.precision\",2)\n",
    "pd.set_option(\"display.max_rows\",30)\n",
    "pd.set_option(\"display.max_columns\",40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_reset():\n",
    "    global df,target,target_donation_amount\n",
    "    raw_df = pd.read_csv(\"Donors_dataset.csv\")\n",
    "    df = raw_df.drop([\"FILE_AVG_GIFT\",\"CONTROL_NUMBER\"],axis = 1).copy()\n",
    "    ordered_names = list(df.columns)\n",
    "    ordered_names.sort()\n",
    "    df = df[ordered_names]\n",
    "    #column names to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.reset_index(inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset()\n",
    "raw_df = pd.read_csv(\"Donors_dataset.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LABEL ENCODING:** Used for exploring correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(df):\n",
    "    df_reset()\n",
    "    df.recency_status_96nk = df.recency_status_96nk.map( {'E':0,'L':1,'F':2, 'N':3, 'A':4, 'S':5} ).astype('int64')\n",
    "    df.frequency_status_97nk = df.frequency_status_97nk.map( {4:'A',3:'B',2:'C', 1:'D'} )\n",
    "    df['donor_gender'].values[df.donor_gender == 'A'] = 'F'\n",
    "    df.donor_gender = df.donor_gender.map( {'F': 1, 'M': 0,'U':3} ).astype('int64')\n",
    "    df.home_owner = df.home_owner.map( {'H': 1, 'U': 0} ).astype('int64')\n",
    "    df.overlay_source = df.overlay_source.map({'P':1, 'B':2, 'N':3, 'M':4})\n",
    "    df.urbanicity = df.urbanicity.map({'U':1,'C':2,'S':3,'T':4,'R':5,'?':6})\n",
    "    df['ses'].values[df.ses == '?'] = 5\n",
    "    df.ses = df.ses.astype('int64')\n",
    "    return df\n",
    "df_label_encoded =label_encode(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix with correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = raw_df.reindex(sorted(raw_df.columns), axis=1)\n",
    "corrmat = sorted_df.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=1., vmin=-.5, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's check the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = df.dtypes\n",
    "types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster_code analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_vals = df.cluster_code.unique()\n",
    "sorted(unique_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there's a messy '.' that should be addressed, so let's investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.cluster_code =='.')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variable highly correlates with urbanicity and ses values. Let's look into that. First let's look at the unique values of cluster code for each urbanicity value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_values = ['U','C','S','T','R','?']\n",
    "urb_cluster = df[['urbanicity', 'cluster_code']]\n",
    "grouped = urb_cluster.groupby('urbanicity').groups\n",
    "print('Urbanicity   :   Unique cluster values')\n",
    "for key in urban_values:\n",
    "    print(key, '   :   ', sorted(urb_cluster.cluster_code.iloc[grouped[key]].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clearly, there is straighforward connection between cluster_code and urbanicity. Let's how it relates to ses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_values = ['1', '2' , '3', '4','?']\n",
    "ses_cluster = df[['ses', 'cluster_code']]\n",
    "grouped = ses_cluster.groupby('ses').groups\n",
    "for key in ses_values:\n",
    "    print(key, ':', sorted(ses_cluster.cluster_code.iloc[grouped[key]].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationship between these two values is not so obvious as with urbanicity. Still, each cluster_code value only corresponds to one value of ses. Also the values of '.' and '?' correspond to missing data in all three fields. This indicates that there might be some problem with those data points so they should not be imputed but given their own value. Even so, both approaches were tried and there was not a significant change in the results. One thing that should be noted is that urbanicity is then the corresponding of a binned version of cluster code, however the same doesn't hold for ses. Also, since there are many of cluster_code for each value of ses/urbanicity, cluster code probably has more information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_cluster_code_date = df[df.cluster_code == '.']\n",
    "print(weird_cluster_code_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally decided to take out all the elements that have cluster code '.' as these points have weird data all over.\n",
    "\n",
    "Furthermore, no data preprocessing was necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Donor gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.donor_gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the values A and U are problematic. We impute A with F, and make U into it's own class of number 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputation\n",
    "df['donor_gender'].values[df.donor_gender == 'A'] = 'F'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check everything is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.donor_gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's put the gender into a binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.donor_gender = df.donor_gender.map( {'F': 1, 'M': 0, 'U': 3} ).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's check what are the most correlated variables correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_encoded.corr().abs()['donor_gender'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.home_owner = df.home_owner.map( {'H': 1, 'U': 0} ).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data= df,x='donor_gender',y='home_owner').set_title('Fraction of home_owners by donor gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a very low correlation with all the variables and it is barely noticeable in the graph. Probably best to leave the U values as they are. Even so, an approach where the U values were imputed with the mode was also tried but it didn't yield better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Donor age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset()\n",
    "df.donor_age.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donor age has many missing values, we'll start out by imputing with the average, but first let's take a look at the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.donor_age.fillna(value=df.donor_age.mean(),inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are some outliers that should be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sorted(df.donor_age)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probably there are no donors aged less than 5 years old and it is a mistake (pssibly even more, but since it will be binned it doesn't matter). For now, let's replace the values with the mean (should be mean of donors with age above 5 years old. Otherwise you include the \"wrong\" ages!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_encoded.corr().abs()['donor_age'].sort_values(ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(df.donor_age,bins=[0,20,30,40,50,70,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_bin'] = pd.cut(df.donor_age,bins=[0,20,30,40,50,70,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df,x=\"age_bin\",y=\"months_since_origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age_bin[df.age_bin==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_bin'] = pd.cut(df.donor_age,bins=[0,20,30,40,50,70,80,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df, x=\"age_bin\",y=\"months_since_origin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this variable is nicely correlated with donor_age which means that it can be used in order to impute donor_age. However, there are a few problems with this relationship. First, the fact that there are  so many values bellow 20 in donor_age. In fact, upon further investigation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.donor_age.sort_values()[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ages are surely a mistake. Let's look at what the sorted values of months_since_origin are for this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['donor_age','months_since_origin']].sort_values(by=['donor_age','months_since_origin'],ascending =[True,False])[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of things to note. The first one is that these low age entries actually have the highest values of months_since_origin in the whole dataset. Given the chart presented above and the clear correlation between the two variables this might indicate that perhaps the mistake is that perhaps the system was not prepared to receive values higher than 100 in the age field so age=0 might actually correspond to 100. Also the maximum value for the age is only 87. However, there are two other points that go against this theory. The first would be that the high months_since_origin values stop abruptly at the age of 18 and the other one being that we have less 0 age values than 2, and less 2 values than 6 and so on. If that number indicated the age in the hundreds, it would be the other way around. Given all this weirdness, the final decision was to transform all the ages bellow 18 to nan and impute everything according to the average donor age value by months_since_origin. \n",
    "\n",
    "This is not such an easy task as it may seem. Initially, it was planned to impute the nan values according to the the mean for a given 'months_since_origin' value. This would be that table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_table = df[['months_since_origin','donor_age']][df.donor_age.notnull()].groupby(['months_since_origin']).mean()\n",
    "impute_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that there are values of months_since_origin that only have nan in the donor_age field, so it's not possible to have a value of reference for that value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_unique_vals = []\n",
    "for i in df.months_since_origin[df.donor_age.isnull()].unique():\n",
    "    if i not in impute_table.index:\n",
    "        nan_unique_vals.append(i)\n",
    "\n",
    "print ('list with values of months_since origin that don\\'t have any age value:',nan_unique_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the relationship between these variables seem to be linear (excluding those with less than 18 years old), it was decided to impute the above mentioned with a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "df.loc[df.donor_age <=18,'donor_age']=np.NaN\n",
    "X = df.months_since_origin[df.donor_age.notnull()].values.reshape(-1,1)\n",
    "y = df.donor_age[df.donor_age.notnull()].values.reshape(-1,1)\n",
    "impute_fit=LinearRegression()\n",
    "impute_fit = impute_fit.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nan_age_index in df.donor_age[df.donor_age.isnull()].index:\n",
    "    if df.months_since_origin.iloc[nan_age_index] in nan_unique_vals:\n",
    "        #impute with model in case there is no base reference to impute\n",
    "        df.at[nan_age_index,'donor_age'] = impute_fit.predict(df.months_since_origin.loc[nan_age_index].reshape(1,-1)).flatten()\n",
    "    else:\n",
    "        #impute according to impute_table otherwise\n",
    "        df.at[nan_age_index,'donor_age'] = impute_table.loc[df.months_since_origin.iloc[nan_age_index]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File card gift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file_card_gift.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df.file_card_gift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "everything seems in order, let's just convert to float as it is a dollar amount (and other dollar amounts are also in floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file_card_gift = df.file_card_gift.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FREQUENCY_STATUS_97NK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.frequency_status_97nk.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding was tested but it yielded worse results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Home owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.home_owner.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are many unknown values. Let's just turn this into a binary variable for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.home_owner = df.home_owner.map( {'H': 1, 'U': 0} ).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.income_group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.income_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this should be a categorical variable (int) but it's in float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.displot(df.income_group,kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.income_group.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are many null values. Let's create a different category (value 0) for them for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.income_group = df.income_group.fillna(value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.income_group = df.income_group.astype('int64')\n",
    "df.income_group.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this column should be a normal distribution even though it doesn't look a lot like one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_encoded.corr().abs()['income_group'].sort_values(ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the median_household_income values corresponding to nan in income group are of good quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['income_group','median_household_income']][df.income_group.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "they seem like they are. Let's visualize the relationship between these two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df,x=\"income_group\",y=\"median_household_income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like it's perfecto to serve as basis for imputation. Just note that we should impute median_household_income first since there are a handfull of zero values that should be filled first. Also note that the mean for imputation is rounded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing median_household_income first\n",
    "#set the 0 to nan\n",
    "df.loc[df.median_household_income == 0,'median_household_income']=np.NaN\n",
    "#group by urbanicity and ses, calculate average and use that\n",
    "df['median_household_income'] = df.groupby(['ses','urbanicity'], sort=False)['median_household_income'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, since this a continuous variable, it should be binned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning\n",
    "df['median_household_bin'] = pd.qcut(df.median_household_income,7,labels=False)\n",
    "#imputation\n",
    "df['income_group'] = df.groupby(['median_household_bin'], sort=False)['income_group'].apply(lambda x: x.fillna(x.mean())).copy()\n",
    "df['income_group'] = df['income_group'].round()\n",
    "df.drop('median_household_bin',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also this variable should be one-hot encoded, to let's convert it to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income_group'] = df['income_group'].astype('str')\n",
    "df['income_group'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.in_house.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last gift amount AND Lifetime* variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this section includes \n",
    "* **LAST_GIFT_AMT** - amount of the most recent donation from the individual to the charitable organization\n",
    "* **LIFETIME_AVG_GIFT_AMT** - lifetime average donation (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_CARD_PROM** - total number of card promotions sent to the individual by the charitable organization\n",
    "* **LIFETIME_GIFT_AMOUNT** - total lifetime donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_COUNT** - total number of donations from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_RANGE** - maximum donation amount from the individual minus minimum donation amount from the individual\n",
    "* **LIFETIME_MAX_GIFT_AMT** - maximum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_MIN_GIFT_AMT** - minimum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_PROM** - total number of promotions sent to the individual by the charitable organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning and outlier treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To guarentee that the binning makes sense, a threshold should be employed so that most bins aren't empty because of the outliers. Let's look at the Last_gift_amt column as an example. The distribution goes like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df.last_gift_amt,kde=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the above features, outlier treatment and binning was applied. For outlier treatment we decided upon thresholds of 3 standard deviations above and below the average of the feature. For the above example that would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_threshold = df['last_gift_amt'].mean()+3*df['last_gift_amt'].std()\n",
    "print(upper_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which makes a lot of sense!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MEDIAN HOME VALUE</b> - median home value (in 100$) as determined by other input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median_home_value.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df.median_home_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median_home_value.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the connections with urbanicity and SES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['U','C','S','T','R','?']\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "sns.countplot(x=df[\"urbanicity\"],hue_order=order, order =order, ax = axs[0]).set_title('Urbanicity for whole dataset')\n",
    "sns.countplot(x=df[df.median_home_value ==0][\"urbanicity\"],hue_order=order, order =order, ax = axs[1]).set_title('Urbanicity for MHV=0')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ses.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['?', '2', '1', '3', '4']\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "sns.countplot(x=df[\"ses\"],hue_order=order, order =order, ax = axs[0]).set_title('SES for whole dataset')\n",
    "sns.countplot(x=df[df.median_home_value ==0][\"ses\"],hue_order=order, order =order, ax = axs[1]).set_title('SES for MHV=0')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems like these values tend to be more urban and in the case of ses the distribution of values is clearly skewed to the right comparing with all the data, but that doesn't tell us too much. Let's check if there is a correlation with age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df[df.median_home_value==0]['donor_age'])\n",
    "sns.kdeplot(df['donor_age'])\n",
    "plt.legend(labels=['MHV = 0', 'all data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems like these are younger donors. Let's what are the variables that correlate the most with median_home_value in order to impute according to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_encoded.corr().abs()['median_home_value'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per_capita_income could be a good candidate. Let's check if it has integrity enough to base our imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.median_home_value==0]['per_capita_income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most values are zero, so not good enough. That could be a reason in fact why there is a high correlation between these is so high. Let's check the next candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.median_home_value==0]['median_household_income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the fact that almost everything is zero is suspicious. Let's count some of these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.median_household_income==0) & (df.per_capita_income==0)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.median_home_value==0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.per_capita_income==0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 173 data points that have 0 on these three fields. This will help us treating these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "income_group also has many Nans. Imputing based on urbanicity and ses seems like a good strategy since earlier it was seen that there is a relationship between these points that that value. Also it makes sense intuitively that house value is related with socioeconomic status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the 0 to nan\n",
    "df.loc[df.median_home_value == 0,'median_home_value']=np.NaN\n",
    "#group by urbanicity and ses, calculate average and use that\n",
    "df['median_home_value'] = df.groupby(['ses','urbanicity'], sort=False)['median_home_value'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MEDIAN HOUSEHOLD INCOME</b> - median household income (in 100$) as determined by other input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df.median_household_income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a weird peak at 0. Instead of filling zero values with the mean we follow the same strategy as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the 0 to nan\n",
    "df.loc[df.median_household_income == 0,'median_household_income']=np.NaN\n",
    "#group by urbanicity and ses, calculate average and use that\n",
    "df['median_household_income'] = df.groupby(['ses','urbanicity'], sort=False)['median_household_income'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MONTHS SINCE FIRST GIFT</b> - number of months since the first donation from the individual to the charitable organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset()\n",
    "df.months_since_first_gift.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be outlier corrected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MONTHS SINCE LAST GIFT</b> - number of months since the most recent donation from the individual to the charitable organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.months_since_last_gift.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.months_since_first_gift.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be outlier corrected!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MONTHS SINCE LAST PROM RESP</b> - number of months since the individual has responded to a promotion by the charitable organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.months_since_last_prom_resp.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.months_since_last_prom_resp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently a float but should be int - checking why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.months_since_last_prom_resp.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df.months_since_last_prom_resp)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are negative values which is weird (cannot have negative time) - changing these to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['months_since_last_prom_resp'].values[df.months_since_last_prom_resp<1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df.months_since_last_prom_resp)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.months_since_last_prom_resp.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "246 null values - changing these for the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.months_since_last_prom_resp.fillna(value=df.months_since_last_prom_resp.mean(),inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now changing from float to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.months_since_last_prom_resp = df.months_since_last_prom_resp.astype('int64')\n",
    "df.months_since_last_prom_resp.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MONTHS SINCE ORIGIN</b> - number of months that the individual has been in the charitable organization's database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.months_since_origin.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.months_since_origin.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MOR HIT RATE</b> - total number of known times the donor has responded to a mailed solicitation from a group other than the charitable organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mor_hit_rate.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.mor_hit_rate[df.mor_hit_rate<10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NUMBER PROM 12</b> - number of promotions (card or other) sent to the individual by the charitable organization in the past 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.number_prom_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.number_prom_12.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.number_prom_12.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>OVERLAY_SOURCE</b> - the data source against which the individual was matched: M if Metromail, P if Polk, B if both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.overlay_source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.overlay_source = df.overlay_source.map( {'M':0,'P':1,'B':2 } ).astype('int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PCT_ATTRIBUTE1</b> - percent of residents in the neighborhood in which the individual lives that are males and active military"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pct_attribute1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.pct_attribute1[df.pct_attribute1<10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PCT_ATTRIBUTE2</b> - percent of residents in the neighborhood in which the individual lives that are males and veterans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pct_attribute2.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pct_attribute2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PCT_ATTRIBUTE3</b> - percent of residents in the neighborhood in which the individual lives that are Vietnam veterans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pct_attribute3.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pct_attribute3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PCT_ATTRIBUTE4</b> - percent of residents in the neighborhood in which the individual lives that are WWII veterans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pct_attribute4.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pct_attribute4.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PCT_OWNER_OCCUPIED</b> - percent of owner-occupied housing in the neighborhood in which the individual lives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pct_owner_occupied.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pct_owner_occupied.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCT data is clean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pep star "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's a binary variable, with no nulls, so everything is fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per Capita Income "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.per_capita_income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was found during the exploration of median_house_value that there are some 0 values that are probably errors in the data. Here we follow the same strategy replacing those values with the average by urbanicity and SES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the 0 to nan\n",
    "df.loc[df.per_capita_income == 0,'per_capita_income']=np.NaN\n",
    "#group by urbanicity and ses, calculate average and use that\n",
    "df['per_capita_income'] = df.groupby(['ses','urbanicity'], sort=False)['per_capita_income'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Published phone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's a binary variable, with no nulls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recency status 96nk\n",
    "description: recency status as of two years ago: A if active donor, S if star donor, N if new donor, E if inactive donor, F if first time donor, L if lapsing donor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.recency_status_96nk.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoding was tried but yielded worse results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RECENT_AVG_CARD_GIFT_AMT\n",
    "average donation from the individual in response to a card solicitation from the charitable organization since four years ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot( df['recent_avg_card_gift_amt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RECENT_AVG_GIFT_AMT\n",
    "average donation (in \\\\$) from the individual to the charitable organization since four years ago\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.recent_avg_gift_amt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data looks fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RECENT_CARD_RESPONSE_COUNT\n",
    "number of times the individual has responded to a card solicitation from the charitable organization since four years ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.recent_card_response_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RECENT_CARD_RESPONSE_PROP\n",
    "proportion of responses to the individual to the number of card solicitations from the charitable organization since four years ago\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.recent_card_response_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note:** ideas to try\n",
    "* bin variable\n",
    "* could be done in categories as most is under 0.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RECENT_RESPONSE_COUNT\n",
    "number of times the individual has responded to a promotion (card or other) from the charitable organization since four years ago\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.recent_response_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note:** ideas to try\n",
    "* bin variable\n",
    "* bins 0,1,2,3,4,5,6,>7?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RECENT_RESPONSE_PROP\n",
    "proportion of responses to the individual to the number of (card or other) solicitations from the charitable organization since four years ago\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.recent_response_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data looks fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RECENT_STAR_STATUS\n",
    "1 if individual has achieved star donor status since four years ago, 0 if not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.recent_star_status.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to do with values above 1. Let's see whether these people have donated and whether they look like people with star status 1. Probably need clustering to check this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.recent_star_status > 0].sort_values(by = ['lifetime_gift_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What to do with all the values > 1?**\n",
    "\n",
    "Replace with 1: When looking at the lifetime_gift_amount, they have donated a lot, so it is probable that they should have received star status. Therefore, imputing with 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recent_star_status'].values[df.recent_star_status > 1] = 1\n",
    "df.recent_star_status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SES\n",
    "one of 5 possible socioeconomic codes classifying the neighborhood in which the individual lives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset()\n",
    "df.ses.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weird '?' value correspond to the weird '.' value in the cluster code feature. Therefore, these are already taken out by that error removal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URBANICITY\n",
    "classification of the neighborhood in which the individual lives: U if urban, C if city, S if suburban, T if town, R if rural, ? if missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.urbanicity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as for SES, '?' values are simply removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WEALTH_RATING\n",
    "one of 10 possible wealth rating groups based on a number of demographic characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.wealth_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wealth_rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_encoded.corr().abs()['wealth_rating'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df,x=\"wealth_rating\",y=\"median_household_income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the same strategy as in income_group will be adopted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning\n",
    "df['median_household_bin'] = pd.qcut(df.median_household_income,9,labels=False)\n",
    "#imputation\n",
    "df['wealth_rating'] = df.groupby(['median_household_bin'], sort=False)['wealth_rating'].apply(lambda x: x.fillna(x.mean())).copy()\n",
    "df['wealth_rating'] = df['wealth_rating'].round()\n",
    "df.drop('median_household_bin',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to help with the rest of the EDA we'll use the pandas profilling tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data and drop duplicates or irrelevant\n",
    "raw_df = pd.read_csv(\"Donors_dataset.csv\")\n",
    "df = raw_df.drop([\"FILE_AVG_GIFT\",\"CONTROL_NUMBER\"],axis = 1)\n",
    "\n",
    "#reorder df columns in alphabetical order\n",
    "ordered_names = list(df.columns)\n",
    "ordered_names.sort()\n",
    "df = df[ordered_names]\n",
    "#column names to lowercase\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the following to install pandas-proffiling conda install -c conda-forge pandas-profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"df Report\",explorative=True)\n",
    "\n",
    "profile.to_widgets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
